{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6e13eef3f5d"
   },
   "source": [
    "##### Copyright 2025 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-02-28T07:39:24.011577Z",
     "iopub.status.busy": "2025-02-28T07:39:24.010656Z",
     "iopub.status.idle": "2025-02-28T07:39:24.035703Z",
     "shell.execute_reply": "2025-02-28T07:39:24.034263Z",
     "shell.execute_reply.started": "2025-02-28T07:39:24.011515Z"
    },
    "id": "d6597b11df14",
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title Licenciado bajo la Licencia Apache, Versión 2.0 (la \"Licencia\");\n",
    "# no puedes usar este archivo excepto en cumplimiento con la Licencia.\n",
    "# Puedes obtener una copia de la Licencia en\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# A menos que lo requiera la ley aplicable o se acuerde por escrito, el software\n",
    "# distribuido bajo la Licencia se distribuye \"TAL CUAL\",\n",
    "# SIN GARANTÍAS NI CONDICIONES DE NINGÚN TIPO, ya sean expresas o implícitas.\n",
    "# Consulta la Licencia para conocer el lenguaje específico que rige los permisos\n",
    "# y limitaciones bajo la Licencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KDIFPAL2EnL"
   },
   "source": [
    "# Día 4 - Ajuste fino de un modelo personalizado\n",
    "\n",
    "¡Bienvenido de nuevo al curso de Generative AI de 5 días en Kaggle!\n",
    "\n",
    "En este notebook usarás la API de Gemini para ajustar un modelo personalizado y específico para una tarea. El ajuste fino puede usarse para una variedad de tareas, desde problemas clásicos de PLN como extracción de entidades o resumen, hasta tareas creativas como generación estilizada. Ajustarás un modelo para clasificar el texto (una publicación de un grupo de noticias) en la categoría a la que pertenece (el nombre del grupo de noticias).\n",
    "\n",
    "Este codelab te guía en el ajuste de un modelo con la API. [AI Studio](https://aistudio.google.com/app/tune) también admite la creación de nuevos modelos ajustados directamente en la interfaz web, lo que te permite crear y monitorear modelos rápidamente usando datos de Google Sheets, Drive o tus propios archivos.\n",
    "\n",
    "**Nota**: Recomendamos hacer este codelab primero hoy. Puede haber un período de espera mientras el modelo se ajusta, por lo que si comienzas con este, puedes probar el otro codelab mientras esperas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:48:50.514130Z",
     "iopub.status.busy": "2025-04-02T07:48:50.513748Z",
     "iopub.status.idle": "2025-04-02T07:49:10.461862Z",
     "shell.execute_reply": "2025-04-02T07:49:10.460060Z",
     "shell.execute_reply.started": "2025-04-02T07:48:50.514097Z"
    },
    "id": "9wafTyEH1_xF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip uninstall -qqy jupyterlab  # Elimina paquetes conflictivos no utilizados\n",
    "!pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:49:10.465052Z",
     "iopub.status.busy": "2025-04-02T07:49:10.464654Z",
     "iopub.status.idle": "2025-04-02T07:49:11.954087Z",
     "shell.execute_reply": "2025-04-02T07:49:11.952770Z",
     "shell.execute_reply.started": "2025-04-02T07:49:10.465012Z"
    },
    "id": "T0CBG9xL2PvT",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "genai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4bYX2T72ScK"
   },
   "source": [
    "### Configura tu clave API\n",
    "\n",
    "Para ejecutar la siguiente celda, tu clave API debe estar almacenada en un [secreto de Kaggle](https://www.kaggle.com/discussions/product-feedback/114053) llamado `GOOGLE_API_KEY`.\n",
    "\n",
    "Si aún no tienes una clave API, puedes obtener una de [AI Studio](https://aistudio.google.com/app/apikey). Puedes encontrar [instrucciones detalladas en la documentación](https://ai.google.dev/gemini-api/docs/api-key).\n",
    "\n",
    "Para hacer que la clave esté disponible a través de secretos de Kaggle, elige `Secrets` en el menú `Add-ons` y sigue las instrucciones para agregar tu clave o habilitarla para este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:49:11.956072Z",
     "iopub.status.busy": "2025-04-02T07:49:11.955554Z",
     "iopub.status.idle": "2025-04-02T07:49:12.223295Z",
     "shell.execute_reply": "2025-04-02T07:49:12.221950Z",
     "shell.execute_reply.started": "2025-04-02T07:49:11.956035Z"
    },
    "id": "VuJPY3GK2SLZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25b2127c2052"
   },
   "source": [
    "Si recibiste un error como `No user secrets exist for kernel id ...`, entonces necesitas agregar tu clave API a través de `Add-ons`, `Secrets` **y** habilitarla.\n",
    "\n",
    "![Captura de pantalla de la casilla para habilitar el secreto GOOGLE_API_KEY](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqVA5QFO6n4z"
   },
   "source": [
    "### Explora los modelos disponibles\n",
    "\n",
    "Usarás el método de la API [`TunedModel.create`](https://ai.google.dev/api/tuning#method:-tunedmodels.create) para iniciar el trabajo de ajuste fino y crear tu modelo personalizado. Encuentra un modelo que lo admita a través del endpoint [`models.list`](https://ai.google.dev/api/models#method:-models.list). También puedes encontrar más información sobre el ajuste de modelos en [la documentación de ajuste de modelos](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?lang=python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:49:12.225986Z",
     "iopub.status.busy": "2025-04-02T07:49:12.225628Z",
     "iopub.status.idle": "2025-04-02T07:49:12.475683Z",
     "shell.execute_reply": "2025-04-02T07:49:12.474240Z",
     "shell.execute_reply.started": "2025-04-02T07:49:12.225951Z"
    },
    "id": "coEacWAB6o0G",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.5-flash-001-tuning\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list():\n",
    "    if \"createTunedModel\" in model.supported_actions:\n",
    "        print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peFm0w_0c1CO"
   },
   "source": [
    "## Descarga el conjunto de datos\n",
    "\n",
    "En esta actividad, usarás el mismo conjunto de datos de grupos de noticias que [usaste para entrenar un clasificador en Keras](https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras/). En este ejemplo, usarás un modelo ajustado de Gemini para lograr el mismo objetivo.\n",
    "\n",
    "El [Conjunto de Datos de Texto de 20 Grupos de Noticias](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) contiene 18,000 publicaciones de grupos de noticias sobre 20 temas divididos en conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:49:12.477215Z",
     "iopub.status.busy": "2025-04-02T07:49:12.476866Z",
     "iopub.status.idle": "2025-04-02T07:49:24.294123Z",
     "shell.execute_reply": "2025-04-02T07:49:24.292962Z",
     "shell.execute_reply.started": "2025-04-02T07:49:12.477128Z"
    },
    "id": "bX_kpgnQ9b-Z",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
    "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
    "\n",
    "# Ver lista de nombres de clases para el conjunto de datos\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipafe6ptZFjt"
   },
   "source": [
    "Así es como se ve una sola fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:49:24.295965Z",
     "iopub.status.busy": "2025-04-02T07:49:24.295557Z",
     "iopub.status.idle": "2025-04-02T07:49:24.301543Z",
     "shell.execute_reply": "2025-04-02T07:49:24.300488Z",
     "shell.execute_reply.started": "2025-04-02T07:49:24.295933Z"
    },
    "id": "EtEXcdT39hCB",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03lDs1O4ZQ0-"
   },
   "source": [
    "## Prepara el conjunto de datos\n",
    "\n",
    "Usarás el mismo código de preprocesamiento que usaste para el modelo personalizado en el día 2. Este preprocesamiento elimina información personal, que puede usarse para \"atajar\" a usuarios conocidos de un foro, y formatea el texto para que parezca un poco más como texto regular y menos como una publicación de un grupo de noticias (por ejemplo, eliminando los encabezados de correo). Esta normalización permite que el modelo generalice a texto regular y no dependa demasiado de campos específicos. Si tus datos de entrada siempre van a ser publicaciones de grupos de noticias, puede ser útil dejar esta estructura en su lugar si proporcionan señales genuinas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:49:24.303116Z",
     "iopub.status.busy": "2025-04-02T07:49:24.302711Z",
     "iopub.status.idle": "2025-04-02T07:49:24.673312Z",
     "shell.execute_reply": "2025-04-02T07:49:24.671991Z",
     "shell.execute_reply.started": "2025-04-02T07:49:24.303070Z"
    },
    "id": "IoNYTxpoZgB0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import email\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_newsgroup_row(data):\n",
    "    # Extraer solo el asunto y el cuerpo\n",
    "    msg = email.message_from_string(data)\n",
    "    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n",
    "    # Eliminar cualquier dirección de correo electrónico restante\n",
    "    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n",
    "    # Truncar el texto para que se ajuste a los límites de entrada\n",
    "    text = text[:40000]\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "    # Poner puntos de datos en un dataframe\n",
    "    df = pd.DataFrame(\n",
    "        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n",
    "    )\n",
    "    # Limpiar el texto\n",
    "    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n",
    "    # Emparejar la etiqueta con el índice del nombre del objetivo\n",
    "    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:49:43.573622Z",
     "iopub.status.busy": "2025-04-02T07:49:43.572509Z",
     "iopub.status.idle": "2025-04-02T07:49:47.447228Z",
     "shell.execute_reply": "2025-04-02T07:49:47.445992Z",
     "shell.execute_reply.started": "2025-04-02T07:49:43.573563Z"
    },
    "id": "kvOsUSRWaW4g",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n",
       "1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n",
       "2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n",
       "3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n",
       "4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n",
       "\n",
       "              Class Name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar preprocesamiento a los conjuntos de datos de entrenamiento y prueba\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSKcj5WtadaR"
   },
   "source": [
    "Ahora toma una muestra de los datos. Mantendrás 50 filas para cada categoría para el entrenamiento. Ten en cuenta que esto es incluso menos que el ejemplo de Keras, ya que esta técnica (ajuste fino eficiente en parámetros, o PEFT) actualiza un número relativamente pequeño de parámetros y no requiere entrenar un nuevo modelo o actualizar el modelo grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:49:47.448998Z",
     "iopub.status.busy": "2025-04-02T07:49:47.448710Z",
     "iopub.status.idle": "2025-04-02T07:49:47.504263Z",
     "shell.execute_reply": "2025-04-02T07:49:47.502994Z",
     "shell.execute_reply.started": "2025-04-02T07:49:47.448972Z"
    },
    "id": "0t9Xu6X5akkt",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    # Muestra filas, seleccionando num_samples de cada etiqueta.\n",
    "    df = (\n",
    "        df.groupby(\"Label\")[df.columns]\n",
    "        .apply(lambda x: x.sample(num_samples))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n",
    "    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "TRAIN_NUM_SAMPLES = 50\n",
    "TEST_NUM_SAMPLES = 10\n",
    "# Mantener rec.* y sci.*\n",
    "CLASSES_TO_KEEP = \"^rec|^sci\"\n",
    "\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar el rendimiento base\n",
    "\n",
    "Antes de comenzar a ajustar un modelo, es una buena práctica realizar una evaluación en los modelos disponibles para asegurarte de que puedes medir cuánto ayuda el ajuste.\n",
    "\n",
    "Primero identifica una sola fila de muestra para usar en la inspección visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:49:52.105294Z",
     "iopub.status.busy": "2025-04-02T07:49:52.104893Z",
     "iopub.status.idle": "2025-04-02T07:49:52.112083Z",
     "shell.execute_reply": "2025-04-02T07:49:52.110865Z",
     "shell.execute_reply.started": "2025-04-02T07:49:52.105259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need info on 88-89 Bonneville\n",
      "\n",
      "\n",
      " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
      "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
      "differences are far as features or performance. I am also curious to\n",
      "know what the book value is for prefereably the 89 model. And how much\n",
      "less than book value can you usually get them for. In other words how\n",
      "much are they in demand this time of year. I have heard that the mid-spring\n",
      "early summer is the best time to buy.\n",
      "\n",
      "\t\t\tNeil Gandler\n",
      "\n",
      "---\n",
      "Label: rec.autos\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "sample_row = preprocess_newsgroup_row(newsgroups_test.data[sample_idx])\n",
    "sample_label = newsgroups_test.target_names[newsgroups_test.target[sample_idx]]\n",
    "\n",
    "print(sample_row)\n",
    "print('---')\n",
    "print('Label:', sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasar el texto directamente como un prompt no produce los resultados deseados. El modelo intentará responder al mensaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:49:54.457192Z",
     "iopub.status.busy": "2025-04-02T07:49:54.456192Z",
     "iopub.status.idle": "2025-04-02T07:49:58.006099Z",
     "shell.execute_reply": "2025-04-02T07:49:58.005024Z",
     "shell.execute_reply.started": "2025-04-02T07:49:54.457136Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are right to be confused! Pontiac's Bonneville line in 1988-89 was a bit of a mess. Here's a breakdown:\n",
      "\n",
      "**Bonneville Models Explained**\n",
      "\n",
      "* **Base Bonneville:**  The most basic model. Usually had a 3.8L V6 engine and a more basic interior.\n",
      "\n",
      "* **LE:**  This stood for \"Luxury Edition\" and typically came with a bit more standard equipment, like upgraded upholstery, power options, and possibly a 5.0L V8 engine. \n",
      "\n",
      "* **SE:**  This stood for \"Sport Edition.\" These cars were geared towards a more sporty persona, with features like a firmer suspension, sport wheels, and sometimes a more powerful engine.\n",
      "\n",
      "* **LSE:**  This is where things get tricky. LSE could stand for \"Luxury Sport Edition,\" which combined features from the LE and SE trims. It also sometimes meant \"Limited Sport Edition,\" which typically had unique styling cues and more limited production.\n",
      "\n",
      "* **SSE:**  The \"SSE\" signified \"Special Service Edition.\"  These models had the 5.0L V8 engine and other performance-enhancing features.  The \"SSE\" designation was a bit confusing because sometimes they were just a specific package on a base Bonneville rather than a separate trim level.\n",
      "\n",
      "* **SSEi:**  This was a new model for 1989 and was intended as a high-performance variant of the Bonneville. It came with a larger 3.8L V6 engine with electronic fuel injection and other enhancements.\n",
      "\n",
      "**Book Value and Pricing**\n",
      "\n",
      "It's impossible to give you a precise book value for an '89 Bonneville without knowing the specific model, mileage, condition, and location. However, you can use websites like Kelley Blue Book or Edmunds to get an estimate based on this information. \n",
      "\n",
      "Generally,  you can expect to pay less than book value, especially for cars that are older and have higher mileage.  The demand for classic Bonnevilles can fluctuate depending on the model, condition, and time of year. Mid-spring to early summer is generally a good time to buy, as dealerships may be more willing to negotiate to clear out inventory.\n",
      "\n",
      "**Negotiating**\n",
      "\n",
      "Here are some tips for negotiating a good price:\n",
      "\n",
      "* **Research:**  Know what the fair market value of the car is before you negotiate.\n",
      "* **Be Patient:**  Don't rush into a deal. Take your time and shop around.\n",
      "* **Be Prepared to Walk Away:**  If you're not happy with the price, be prepared to walk away.\n",
      "\n",
      "**Important Considerations**\n",
      "\n",
      "* **Condition:**  A well-maintained Bonneville can be a reliable car, but they can also have issues. Pay close attention to the car's condition and be prepared to spend some money on repairs.\n",
      "* **Parts Availability:**  Parts for older Bonnevilles can be harder to find, so make sure you can get the parts you need if something breaks.\n",
      "\n",
      "**Good luck with your search!** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-1.5-flash-001\", contents=sample_row)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes usar las técnicas de ingeniería de prompts que has aprendido esta semana para inducir al modelo a realizar la tarea deseada. Prueba algunas de tus propias ideas y ve qué es efectivo, o revisa las siguientes celdas para diferentes enfoques. ¡Ten en cuenta que tienen diferentes niveles de efectividad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:50:05.256628Z",
     "iopub.status.busy": "2025-04-02T07:50:05.256079Z",
     "iopub.status.idle": "2025-04-02T07:50:06.077581Z",
     "shell.execute_reply": "2025-04-02T07:50:06.075933Z",
     "shell.execute_reply.started": "2025-04-02T07:50:05.256575Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The message originates from the **alt.autos.pontiac** newsgroup. \n",
      "\n",
      "This is evident from the content of the message, which is specifically focused on a Pontiac model, the Bonneville.  Newsgroup names often reflect the topics discussed within them. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pregunta al modelo directamente en un prompt de cero disparos.\n",
    "\n",
    "prompt = \"¿De qué grupo de noticias proviene el siguiente mensaje?\"\n",
    "baseline_response = client.models.generate_content(\n",
    "    model=\"gemini-1.5-flash-001\",\n",
    "    contents=[prompt, sample_row])\n",
    "print(baseline_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta técnica aún produce una respuesta bastante extensa. Podrías intentar extraer el texto relevante o refinar aún más el prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:50:19.474737Z",
     "iopub.status.busy": "2025-04-02T07:50:19.474289Z",
     "iopub.status.idle": "2025-04-02T07:50:20.185012Z",
     "shell.execute_reply": "2025-04-02T07:50:20.183642Z",
     "shell.execute_reply.started": "2025-04-02T07:50:19.474696Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos.misc\n",
      "\n",
      "Incorrect.\n"
     ]
    }
   ],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "# Puedes usar una instrucción del sistema para hacer un prompt más directo y obtener una\n",
    "# respuesta más concisa.\n",
    "\n",
    "system_instruct = \"\"\"\n",
    "Eres un servicio de clasificación. Se te pasará una entrada que representa\n",
    "una publicación de un grupo de noticias y debes responder con el grupo de noticias del que\n",
    "proviene la publicación.\n",
    "\"\"\"\n",
    "\n",
    "# Define un ayudante para reintentar cuando se alcance la cuota por minuto.\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "# Si deseas evaluar tu propia técnica, reemplaza este cuerpo de esta función\n",
    "# con tu modelo, prompt y otro código y devuelve la respuesta predicha.\n",
    "@retry.Retry(predicate=is_retriable)\n",
    "def predict_label(post: str) -> str:\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-1.5-flash-001\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=system_instruct),\n",
    "        contents=post)\n",
    "\n",
    "    rc = response.candidates[0]\n",
    "\n",
    "    # Cualquier error, filtro, recitación, etc. podemos marcarlo como un error general\n",
    "    if rc.finish_reason.name != \"STOP\":\n",
    "        return \"(error)\"\n",
    "    else:\n",
    "        # Limpiar la respuesta.\n",
    "        return response.text.strip()\n",
    "\n",
    "\n",
    "prediction = predict_label(sample_row)\n",
    "\n",
    "print(prediction)\n",
    "print()\n",
    "print(\"¡Correcto!\" si prediction == sample_label else \"Incorrecto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realiza una breve evaluación usando la función definida anteriormente. El conjunto de prueba se muestrea aún más para garantizar que el experimento se ejecute sin problemas en el nivel gratuito de la API. En la práctica, evaluarías todo el conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:50:36.205338Z",
     "iopub.status.busy": "2025-04-02T07:50:36.204910Z",
     "iopub.status.idle": "2025-04-02T07:51:06.125368Z",
     "shell.execute_reply": "2025-04-02T07:51:06.124235Z",
     "shell.execute_reply.started": "2025-04-02T07:50:36.205304Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20eccde15c242758379f23ebd6f5514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 37.50%\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from tqdm.rich import tqdm as tqdmr\n",
    "import warnings\n",
    "\n",
    "# Habilitar funciones de tqdm en Pandas.\n",
    "tqdmr.pandas()\n",
    "\n",
    "# Pero suprimir la advertencia experimental\n",
    "warnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n",
    "\n",
    "\n",
    "# Muestra aún más los datos de prueba para ser consciente del nivel gratuito.\n",
    "df_baseline_eval = sample_data(df_test, 2, '.*')\n",
    "\n",
    "# Hacer predicciones usando los datos muestreados.\n",
    "df_baseline_eval['Prediction'] = df_baseline_eval['Text'].progress_apply(predict_label)\n",
    "\n",
    "# Y calcular la precisión.\n",
    "accuracy = (df_baseline_eval[\"Class Name\"] == df_baseline_eval[\"Prediction\"]).sum() / len(df_baseline_eval)\n",
    "print(f\"Precisión: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora echa un vistazo al dataframe para comparar las predicciones con las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:51:06.130826Z",
     "iopub.status.busy": "2025-04-02T07:51:06.130340Z",
     "iopub.status.idle": "2025-04-02T07:51:06.144977Z",
     "shell.execute_reply": "2025-04-02T07:51:06.143833Z",
     "shell.execute_reply.started": "2025-04-02T07:51:06.130772Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Re: Too fast\\n\\n (Dan Day) writes:\\n&gt; In artic...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>rec.autos.sports.cars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Re: Information needed...\\n\\n (Youjip Won) wri...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Re: Maxima Chain wax (and mail-order)\\n\\nIn ar...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Shaft-drives and Wheelies \\n\\nIn article &lt;...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Yanks over A's George Speaks\\n\\nIn &lt;&gt;  wri...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>rec.sports.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Re: Bosox go down in smoke II (Seattle 7-0) .....</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Selfish hockey fans..\\n\\n\\n\\tOn Tuesday, when ...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>rec.sports.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Re: Octopus in Detroit?\\n\\nValerie S. Hammerl ...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Re: Let's build software cryptophones for over...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>(error)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Crypto-PenPals\\n\\nI came. I lurked. I read the...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Re: Lead Acid batteries &amp; Concrete?\\n\\nIn arti...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Re: Lead ACid Batteries Part 2!!!\\n\\nIn articl...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Re: Krillean Photography\\n\\nIn article &lt;&gt;  (Al...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>alt.folklore.urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Re: Strain Gage Applications in vivo\\n\\nIn art...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>comp.bio.medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Re: HST Servicing Mission Scheduled for 11 Day...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Re: Why we like DC-X (was Re: Shuttle 0-Defect...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>misc.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Label  \\\n",
       "0   Re: Too fast\\n\\n (Dan Day) writes:\\n> In artic...      7   \n",
       "1   Re: Information needed...\\n\\n (Youjip Won) wri...      7   \n",
       "2   Re: Maxima Chain wax (and mail-order)\\n\\nIn ar...      8   \n",
       "3   Re: Shaft-drives and Wheelies \\n\\nIn article <...      8   \n",
       "4   Re: Yanks over A's George Speaks\\n\\nIn <>  wri...      9   \n",
       "5   Re: Bosox go down in smoke II (Seattle 7-0) .....      9   \n",
       "6   Selfish hockey fans..\\n\\n\\n\\tOn Tuesday, when ...     10   \n",
       "7   Re: Octopus in Detroit?\\n\\nValerie S. Hammerl ...     10   \n",
       "8   Re: Let's build software cryptophones for over...     11   \n",
       "9   Crypto-PenPals\\n\\nI came. I lurked. I read the...     11   \n",
       "10  Re: Lead Acid batteries & Concrete?\\n\\nIn arti...     12   \n",
       "11  Re: Lead ACid Batteries Part 2!!!\\n\\nIn articl...     12   \n",
       "12  Re: Krillean Photography\\n\\nIn article <>  (Al...     13   \n",
       "13  Re: Strain Gage Applications in vivo\\n\\nIn art...     13   \n",
       "14  Re: HST Servicing Mission Scheduled for 11 Day...     14   \n",
       "15  Re: Why we like DC-X (was Re: Shuttle 0-Defect...     14   \n",
       "\n",
       "            Class Name                Prediction  \n",
       "0            rec.autos     rec.autos.sports.cars  \n",
       "1            rec.autos  comp.sys.ibm.pc.hardware  \n",
       "2      rec.motorcycles           rec.motorcycles  \n",
       "3      rec.motorcycles           rec.motorcycles  \n",
       "4   rec.sport.baseball       rec.sports.baseball  \n",
       "5   rec.sport.baseball        rec.sport.baseball  \n",
       "6     rec.sport.hockey         rec.sports.hockey  \n",
       "7     rec.sport.hockey          rec.sport.hockey  \n",
       "8            sci.crypt                   (error)  \n",
       "9            sci.crypt                 sci.crypt  \n",
       "10     sci.electronics            rec.autos.misc  \n",
       "11     sci.electronics            rec.autos.misc  \n",
       "12             sci.med        alt.folklore.urban  \n",
       "13             sci.med          comp.bio.medical  \n",
       "14           sci.space                 sci.space  \n",
       "15           sci.space                misc.space  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok7ugrLzcghX"
   },
   "source": [
    "## Ajustar un modelo personalizado\n",
    "\n",
    "En este ejemplo, usarás el ajuste fino para crear un modelo que no requiera instrucciones del sistema ni prompts y que produzca texto conciso de las clases que proporcionas en los datos de entrenamiento.\n",
    "\n",
    "Los datos contienen tanto texto de entrada (las publicaciones procesadas) como texto de salida (la categoría, o grupo de noticias), que puedes usar para comenzar a ajustar un modelo.\n",
    "\n",
    "Al llamar a `tune()`, puedes especificar los hiperparámetros de ajuste del modelo también:\n",
    " - `epoch_count`: define cuántas veces recorrer los datos,\n",
    " - `batch_size`: define cuántas filas procesar en un solo paso, y\n",
    " - `learning_rate`: define el factor de escala para actualizar los pesos del modelo en cada paso.\n",
    "\n",
    "También puedes optar por omitirlos y usar los valores predeterminados. [Aprende más](https://developers.google.com/machine-learning/crash-course/linear-regression/hyperparameters) sobre estos parámetros y cómo funcionan. Para este ejemplo, estos parámetros se seleccionaron ejecutando algunos trabajos de ajuste y seleccionando parámetros que convergieron eficientemente.\n",
    "\n",
    "Este ejemplo iniciará un nuevo trabajo de ajuste, pero solo si no existe uno ya. Esto te permite dejar este codelab y volver más tarde: volver a ejecutar este paso encontrará tu último modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:55:53.142071Z",
     "iopub.status.busy": "2025-04-02T07:55:53.141652Z",
     "iopub.status.idle": "2025-04-02T07:55:55.004654Z",
     "shell.execute_reply": "2025-04-02T07:55:55.003495Z",
     "shell.execute_reply.started": "2025-04-02T07:55:53.142034Z"
    },
    "id": "pWOZlspfY8dV",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45/3257069937.py:40: ExperimentalWarning: The SDK's tuning implementation is experimental, and may change in future versions.\n",
      "  tuning_op = client.tunings.tune(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_QUEUED\n",
      "tunedModels/newsgroup-classification-model-yyxc6vlgd\n"
     ]
    }
   ],
   "source": [
    "from collections.abc import Iterable\n",
    "import random\n",
    "\n",
    "\n",
    "# Convertir el dataframe en un conjunto de datos adecuado para el ajuste.\n",
    "input_data = {'examples': \n",
    "    df_train[['Text', 'Class Name']]\n",
    "      .rename(columns={'Text': 'textInput', 'Class Name': 'output'})\n",
    "      .to_dict(orient='records')\n",
    " }\n",
    "\n",
    "# Si estás volviendo a ejecutar este laboratorio, agrega tu model_id aquí.\n",
    "model_id = None\n",
    "\n",
    "# O intenta encontrar un trabajo de ajuste reciente.\n",
    "if not model_id:\n",
    "  queued_model = None\n",
    "  # Modelos más nuevos primero.\n",
    "  for m in reversed(client.tunings.list()):\n",
    "    # Solo mira los modelos de clasificación de grupos de noticias.\n",
    "    if m.name.startswith('tunedModels/newsgroup-classification-model'):\n",
    "      # Si hay un modelo completado, usa el primero (más nuevo).\n",
    "      if m.state.name == 'JOB_STATE_SUCCEEDED':\n",
    "        model_id = m.name\n",
    "        print('Se encontró un modelo ajustado existente para reutilizar.')\n",
    "        break\n",
    "\n",
    "      elif m.state.name == 'JOB_STATE_RUNNING' and not queued_model:\n",
    "        # Si hay un modelo aún en cola, recuerda el más reciente.\n",
    "        queued_model = m.name\n",
    "  else:\n",
    "    if queued_model:\n",
    "      model_id = queued_model\n",
    "      print('Se encontró un modelo en cola, aún esperando.')\n",
    "\n",
    "\n",
    "# Subir los datos de entrenamiento y poner en cola el trabajo de ajuste.\n",
    "if not model_id:\n",
    "    tuning_op = client.tunings.tune(\n",
    "        base_model=\"models/gemini-1.5-flash-001-tuning\",\n",
    "        training_dataset=input_data,\n",
    "        config=types.CreateTuningJobConfig(\n",
    "            tuned_model_display_name=\"Modelo de clasificación de grupos de noticias\",\n",
    "            batch_size=16,\n",
    "            epoch_count=2,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    print(tuning_op.state)\n",
    "    model_id = tuning_op.name\n",
    "\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQ3YZ2MBubCY"
   },
   "source": [
    "Esto ha creado un trabajo de ajuste que se ejecutará en segundo plano. Para inspeccionar el progreso del trabajo de ajuste, ejecuta esta celda para trazar el estado actual y la curva de pérdida. Una vez que el estado alcance `ACTIVE`, el ajuste estará completo y el modelo estará listo para usar.\n",
    "\n",
    "Los trabajos de ajuste se ponen en cola, por lo que puede parecer que no se han realizado pasos de entrenamiento inicialmente, pero progresará. El ajuste puede tardar desde unos minutos hasta varias horas, dependiendo de factores como el tamaño de tu conjunto de datos y qué tan ocupada esté la infraestructura de ajuste. ¿Por qué no te tomas una taza de té mientras esperas, o vienes a decir \"¡Hola!\" en el grupo [Discord](https://discord.com/invite/kaggle).\n",
    "\n",
    "Es seguro detener esta celda en cualquier momento. No detendrá el trabajo de ajuste.\n",
    "\n",
    "**IMPORTANTE**: Debido al alto volumen de usuarios que realizan este curso, los trabajos de ajuste pueden estar en cola durante muchas horas. Toma nota de tu ID de modelo ajustado arriba (`tunedModels/...`) para que puedas volver a él mañana. Mientras tanto, revisa el codelab de [Búsqueda de Google](https://www.kaggle.com/code/markishere/day-4-google-search-grounding/). Si deseas intentar ajustar un LLM local, revisa [las guías de ajuste para ajustar un modelo Gemma](https://ai.google.dev/gemma/docs/tune)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T08:11:13.878725Z",
     "iopub.status.busy": "2025-04-02T08:11:13.878313Z",
     "iopub.status.idle": "2025-04-02T08:11:15.417549Z",
     "shell.execute_reply": "2025-04-02T08:11:15.416441Z",
     "shell.execute_reply.started": "2025-04-02T08:11:13.878693Z"
    },
    "id": "c4ef5f13692d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_RUNNING\n",
      "Taking a shortcut, using a previously prepared model.\n",
      "Done! The model state is: JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "MAX_WAIT = datetime.timedelta(minutes=10)\n",
    "\n",
    "while not (tuned_model := client.tunings.get(name=model_id)).has_ended:\n",
    "\n",
    "    print(tuned_model.state)\n",
    "    time.sleep(60)\n",
    "\n",
    "    # No esperes demasiado. Usa un modelo público si esto va a tardar mucho.\n",
    "    if datetime.datetime.now(datetime.timezone.utc) - tuned_model.create_time > MAX_WAIT:\n",
    "        print(\"Tomando un atajo, usando un modelo preparado previamente.\")\n",
    "        model_id = \"tunedModels/newsgroup-classification-model-ltenbi1b\"\n",
    "        tuned_model = client.tunings.get(name=model_id)\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"¡Hecho! El estado del modelo es: {tuned_model.state.name}\")\n",
    "\n",
    "if not tuned_model.has_succeeded and tuned_model.error:\n",
    "    print(\"Error:\", tuned_model.error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-qiIdK4u80z"
   },
   "source": [
    "## Usa el nuevo modelo\n",
    "\n",
    "Ahora que tienes un modelo ajustado, pruébalo con datos personalizados. Usas la misma API que una interacción normal de la API de Gemini, pero especificas tu nuevo modelo como el nombre del modelo, que comenzará con `tunedModels/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T08:11:24.916590Z",
     "iopub.status.busy": "2025-04-02T08:11:24.915979Z",
     "iopub.status.idle": "2025-04-02T08:11:27.566345Z",
     "shell.execute_reply": "2025-04-02T08:11:27.564861Z",
     "shell.execute_reply.started": "2025-04-02T08:11:24.916540Z"
    },
    "id": "hyO2-MXLvM6a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.space\n"
     ]
    }
   ],
   "source": [
    "new_text = \"\"\"\n",
    "Primerizo buscando salir de aquí.\n",
    "\n",
    "Hola, estoy escribiendo sobre mi interés en viajar a los límites exteriores.\n",
    "\n",
    "¿Qué tipo de nave puedo comprar? ¿Qué es lo más fácil de acceder desde esta tercera roca?\n",
    "\n",
    "Déjame saber cómo hacer eso, por favor.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_id, contents=new_text)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xajLek9DySH_"
   },
   "source": [
    "### Evaluación\n",
    "\n",
    "Puedes ver que el modelo produce etiquetas que corresponden a las del conjunto de datos de entrenamiento, y sin ninguna instrucción del sistema o prompt, lo cual ya es una gran mejora. Ahora ve qué tan bien se desempeña en el conjunto de prueba.\n",
    "\n",
    "Ten en cuenta que no hay paralelismo en este ejemplo; clasificar el subconjunto de prueba tomará unos minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T08:11:29.713129Z",
     "iopub.status.busy": "2025-04-02T08:11:29.712728Z",
     "iopub.status.idle": "2025-04-02T08:14:02.348228Z",
     "shell.execute_reply": "2025-04-02T08:14:02.347128Z",
     "shell.execute_reply.started": "2025-04-02T08:11:29.713082Z"
    },
    "id": "6T2Y3ZApvbMw",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6cb63247f540e88aa82ac77dda8738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "@retry.Retry(predicate=is_retriable)\n",
    "def classify_text(text: str) -> str:\n",
    "    \"\"\"Clasificar el texto proporcionado en un grupo de noticias conocido.\"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=model_id, contents=text)\n",
    "    rc = response.candidates[0]\n",
    "\n",
    "    # Cualquier error, filtro, recitación, etc. podemos marcarlo como un error general\n",
    "    if rc.finish_reason.name != \"STOP\":\n",
    "        return \"(error)\"\n",
    "    else:\n",
    "        return rc.content.parts[0].text\n",
    "\n",
    "\n",
    "# El muestreo aquí es solo para minimizar el uso de tu cuota. Si puedes, deberías\n",
    "# evaluar todo el conjunto de prueba con `df_model_eval = df_test.copy()`.\n",
    "df_model_eval = sample_data(df_test, 4, '.*')\n",
    "\n",
    "df_model_eval[\"Prediction\"] = df_model_eval[\"Text\"].progress_apply(classify_text)\n",
    "\n",
    "accuracy = (df_model_eval[\"Class Name\"] == df_model_eval[\"Prediction\"]).sum() / len(df_model_eval)\n",
    "print(f\"Precisión: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparar el uso de tokens\n",
    "\n",
    "AI Studio y la API de Gemini proporcionan ajuste de modelos sin costo, sin embargo, se aplican límites y cargos normales para el *uso* de un modelo ajustado.\n",
    "\n",
    "El tamaño del prompt de entrada y otra configuración de generación como las instrucciones del sistema, así como el número de tokens de salida generados, todos contribuyen al costo general de una solicitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T08:14:02.353306Z",
     "iopub.status.busy": "2025-04-02T08:14:02.352880Z",
     "iopub.status.idle": "2025-04-02T08:14:02.612742Z",
     "shell.execute_reply": "2025-04-02T08:14:02.611517Z",
     "shell.execute_reply.started": "2025-04-02T08:14:02.353257Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System instructed baseline model: 172 (input)\n",
      "Tuned model: 136 (input)\n",
      "Token savings: 26.47%\n"
     ]
    }
   ],
   "source": [
    "# Calcular el costo de *entrada* del modelo base con instrucciones del sistema.\n",
    "sysint_tokens = client.models.count_tokens(\n",
    "    model='gemini-1.5-flash-001', contents=[system_instruct, sample_row]\n",
    ").total_tokens\n",
    "print(f'Modelo base con instrucciones del sistema: {sysint_tokens} (entrada)')\n",
    "\n",
    "# Calcular el costo de entrada del modelo ajustado.\n",
    "tuned_tokens = client.models.count_tokens(model=tuned_model.base_model, contents=sample_row).total_tokens\n",
    "print(f'Modelo ajustado: {tuned_tokens} (entrada)')\n",
    "\n",
    "savings = (sysint_tokens - tuned_tokens) / tuned_tokens\n",
    "print(f'Ahorro de tokens: {savings:.2%}')  # Ten en cuenta que esto es solo n=1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo extenso anterior también produjo más tokens de salida de los necesarios para esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T08:14:02.615096Z",
     "iopub.status.busy": "2025-04-02T08:14:02.614741Z",
     "iopub.status.idle": "2025-04-02T08:14:03.532486Z",
     "shell.execute_reply": "2025-04-02T08:14:03.531188Z",
     "shell.execute_reply.started": "2025-04-02T08:14:02.615061Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (verbose) output tokens: 52\n",
      "Tuned output tokens: 4\n"
     ]
    }
   ],
   "source": [
    "baseline_token_output = baseline_response.usage_metadata.candidates_token_count\n",
    "print('Tokens de salida del modelo base (extenso):', baseline_token_output)\n",
    "\n",
    "tuned_model_output = client.models.generate_content(\n",
    "    model=model_id, contents=sample_row)\n",
    "tuned_tokens_output = tuned_model_output.usage_metadata.candidates_token_count\n",
    "print('Tokens de salida del modelo ajustado:', tuned_tokens_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6c1204a5d0ab"
   },
   "source": [
    "## Próximos pasos\n",
    "\n",
    "Ahora que has ajustado un modelo de clasificación, prueba algunas otras tareas, como ajustar un modelo para responder con un tono o estilo específico usando ejemplos escritos a mano (¡o incluso ejemplos generados!). Kaggle alberga [una serie de conjuntos de datos](https://www.kaggle.com/datasets) que puedes probar.\n",
    "\n",
    "Aprende sobre [cuándo el ajuste fino supervisado es más efectivo](https://cloud.google.com/blog/products/ai-machine-learning/supervised-fine-tuning-for-gemini-llm).\n",
    "\n",
    "Y revisa el [tutorial de ajuste fino](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?hl=en&lang=python) para otro ejemplo que muestra un modelo ajustado extendiéndose más allá de los datos de entrenamiento a nuevas entradas no vistas.\n",
    "\n",
    "*- [Mark McD](https://linktr.ee/markmcd)*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "day-4-fine-tuning-a-custom-model.ipynb",
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
